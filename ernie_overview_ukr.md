# Огляд китайських моделей ШІ від Alibaba, Baidu та DeepSeek
## Ernie AI

![Ernie](https://upload.wikimedia.org/wikipedia/en/4/42/Ernie_Bot_Logo.png)

ERNIE (Enhanced Representation through Knowledge Integration – розширене представлення через інтеграцію знань) – це серія великих мовних моделей, розроблених Baidu, провідною китайською технологічною компанією. Вони призначені переважно для завдань обробки природної мови з акцентом на можливості китайської мови. Моделі ERNIE чудово обробляють китайський текст, включаючи назви, місця та терміни політики, що робить їх особливо цінними для двомовних китайсько-англійських робочих процесів. Вони підтримують різноманітні завдання, такі як обробка документів (вилучення даних із зображень та PDF-файлів), створення контенту, вивчення мови та перетворення ділових документів з високою точністю та надійними структурованими результатами.[[1]](https://en.wikipedia.org/wiki/Ernie_Bot)

Сімейство моделей ERNIE включає кілька версій, серед яких ERNIE 4.0 є значним оновленням, що пропонує покращені можливості для міркування, розуміння мови та генерації сигналів. ERNIE 4.5 — це новіша мультимодальна модель з розширеними функціями як для текстового, так і для візуального розуміння та міркування, що підтримує як режими мислення, так і режими немислення, та оптимізована для використання мови загального призначення. Вона включає архітектуру зі змішаним підходом експертів, маршрутизацію з ізоляцією модальностей та збалансоване мультимодальне навчання для досягнення успіху в завданнях, що включають текст, зображення та міжмодальне мислення. Ці моделі є потужними у відстеженні інструкцій, знаннях світу та вирішенні складних проблем, тісно конкуруючи з найсучаснішими моделями у світі.

Baidu також надає промисловий інструментарій під назвою ERNIEKit для точного налаштування та ефективного розгортання цих моделей. Моделі ERNIE працюють у чат-ботах Baidu на основі штучного інтелекту, таких як Ernie Bot, який конкурує з такими моделями, як GPT, у китайських завданнях NLP та підтримує різні програми для генерації контенту та вирішення проблем. Baidu випустила першу версію Ernie Bot у березні 2023 року. На той час сервіс базувався на LLM під назвою Ernie 3.0, яку компанія почала розробляти у 2019 році. Модель містила 10 мільярдів параметрів і була навчена на наборі даних розміром 4 терабайти. Baidu прагне зробити свої моделі ERNIE відкритими, плануючи випустити подальші вдосконалені версії, такі як ERNIE 5, для розширення можливостей та сприяння дослідженням і розробкам у галузі штучного інтелекту.[[2]](https://siliconangle.com/2025/02/14/baidu-open-source-ernie-large-language-model-series/)

### Список модель Ernie

| Покоління       | ~Рік      | Примітки                                                                                                                                                 |
| --------------- | --------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ERNIE 1.0       | 2019      | Перша модель попереднього навчання для китайського НЛП.[[3]](https://huggingface.co/papers/1904.09223)                                                   |
| ERNIE 2.0       | 2019      | Платформа постійного попереднього навчання, що розширює ERNIE 1.0.[[4]](https://ojs.aaai.org/index.php/AAAI/article/view/6428)                           |
| ERNIE 3.0       | 2021–2023 | Велика модель, розширена данними; основа раннього Ерні Бота.[[5]](https://huggingface.co/papers/2107.02137)                                              |
| ERNIE 3.0 Titan | 2021–2023 | «Масштабована» версія 3.0 (з набагато більшою кількістю параметрів) для складних завдань.[[6]](https://arxiv.org/abs/2112.12731)                         |
| ERNIE 3.5       | 2023      | Покращено загальний LLM для Ernie Bot з кращим мисленням.[[7]](https://en.wikipedia.org/wiki/Ernie_Bot)                                                  |
| ERNIE 4.0       | 2023–2024 | Високоякісний LLM, нова флагманська модель.                                                                                                              |
| ERNIE 4.0 Turbo | 2024      | Варіант 4.0 з оптимізованою затримкою та витратами.                                                                                                      |
| ERNIE 4.5       | 2025      | Мультимодальне сімейство MoE (10+ варіантів, до 424 млрд параметрів загалом).[[8]](https://ernie.baidu.com/blog/posts/ernie4.5/)                         |
| ERNIE 4.5 Turbo | 2025      | Швидший/дешевший варіант 4.5.                                                                                                                            |
| ERNIE X1        | 2025      | Спеціалізована модель міркування в рамках родини ERNIE.[[9]](https://www.datacamp.com/blog/ernie-4-5-x1)                                                 |
| ERNIE X1 Turbo  | 2025      | Оптимізована модель міркувань для використання з низькою затримкою.                                                                                      |
| ERNIE 5 (ann.)  | 2025      | Модель MoE наступного покоління (запланований наступник версії 4.5)[[10]](https://ernie.baidu.com/blog/posts/ernie-5.0-preview-1120-release-on-lmarena/) |




### Ernie 1.0 та Ernie 2.0[[11]](https://github.com/arita37/ERNIE-1)

Ранні версії (1.0 - 2.0) були переважно моделями «попереднього навчання / навчання представленню», зосередженими на розумінні мови (не повноцінна функціональність мультимодального чат-бота).

ERNIE 1.0 — це метод навчання представленню мови, покращений стратегіями маскування знань, що включає маскування на рівні сутності та маскування на рівні фрази. Натхненний стратегією маскування BERT.[[12]](https://arxiv.org/abs/1810.04805), ERNIE запровадив маскування фраз та маскування іменованих сутностей і передбачає цілі масковані фрази або іменовані сутності. Стратегія на рівні фрази маскує всю фразу, яка є групою слів, що функціонує як концептуальна одиниця. Стратегія на рівні сутності маскує іменовані сутності, включаючи осіб, місця розташування, організації, вироби тощо, які можна позначити власними іменами.

ERNIE 2.0 — це система безперервного попереднього навчання для розуміння мови, в якій завдання попереднього навчання можуть бути поступово створені та вивчені шляхом багатозадачного навчання. У цій системі різні налаштовані завдання можуть бути поступово введені в будь-який час. Наприклад, завдання, що включають прогнозування іменованих сутностей, розпізнавання дискурсних зв'язків, прогнозування порядку речень, використовуються для того, щоб моделі могли вивчати мовні представлення.

#### Порівняння Ernie 1.0 та Ernie 2.0

| Тип задвань             | ERNIE 1.0                       | ERNIE 2.0(en)                                                                           | ERNIE 2.0(zh)                                   |
| ----------------------- | ------------------------------- | --------------------------------------------------------------------------------------- | ----------------------------------------------- |
| Розуміння слів          | Маскування знань                | Маскування знань<br>Прогнозування капіталізації<br>Прогнозування зв'язку токен-документ | Маскування знань                                |
| Усвідомлення структури  | -                               | Переупорядкування речень                                                                | Переупорядкування речень Відстань між реченнями |
| Семантичне усвідомлення | Передбачення наступного речення | Дискурсивний зв'язок                                                                    | Дискурсивний зв'язок IR Релевантність           |


### Продуктивність

#### GLUE-Dev

| <strong>Dataset</strong> | <strong>CoLA</strong> | <strong>SST-2</strong> | <strong>MRPC</strong> | <strong>STS-B</strong> | <strong>QQP</strong> | <strong>MNLI-m</strong> | <strong>QNLI</strong> | <strong>RTE</strong> |
| --------------------- | --------------------- | ---------------------- | --------------------- | ---------------------- | -------------------- | ----------------------- | --------------------- | -------------------- |
| **metric**            | **matthews corr.**    | **acc**                | **acc**          | **pearson corr.**      | **acc**              | **acc**                 | **acc**               | **acc**              |
| **BERT Large**        | 60.6                  | 93.2                   | 88.0                  | 90.0                   | 91.3                 | 86.6                    | 92.3                  | 70.4                 |
| **XLNet Large**       | 63.6          | 95.6   | 89.2   | 91.8    | 91.8  | 89.8   | 93.9   | 83.8   |
| **ERNIE 2.0 Large**   | 65.4<br/>(**+4.8,+1.8**)   | 96.0<br/>(**+2.8,+0.4**)    | 89.7<br/>(**+1.7,+0.5**)   | 92.3<br/>(**+2.3,+0.5**)    | 92.5<br/>(**+1.2,+0.7**)  | 89.1<br/>(**+2.5,-0.7**)     | 94.3<br/>(**+2.0,+0.4**)   | 85.2<br/>(**+14.8,+1.4**) |

#### GLUE-Test

| <strong>Dataset</strong>                | -                          | <strong>CoLA</strong> | <strong>SST-2</strong> | <strong>MRPC</strong>         | <strong>STS-B</strong>        | <strong>QQP</strong>          | <strong>MNLI-m</strong> | <strong>MNLI-mm</strong> | <strong>QNLI</strong> | <strong>RTE</strong> | <strong>WNLI</strong> | <strong>AX</strong> |
| ------------------- | -------------------------- | --------------------- | ---------------------- | ----------------------------- | ----------------------------- | ----------------------------- | ----------------------- | ------------------------ | --------------------- | -------------------- | --------------------- | ------------------- |
| **Metric**          | **<strong>score</strong>** | **matthews corr.**    | **acc**                | **f1-score/acc**              | **spearman/pearson corr.**    | **f1-score/acc**              | **acc**                 | **acc**                  | **acc**               | **acc**              | **acc**               | **matthews corr.**  |
| **BERT Base**       | 78.3                       | 52.1                  | 93.5                   | 88.9/84.8                     | 85.8/87.1                     | 71.2/89.2                     | 84.6                    | 83.4                     | 90.5                  | 66.4                 | 65.1                  | 34.2                |
| **ERNIE 2.0 Base**  | 80.6<br/>(**+2.3**)        | 55.2<br/>(**+3.1**)   | 95.0<br/>(**+1.5**)    | 89.9/86.1<br/>(**+1.0/+1.3**) | 86.5/87.6<br/>(**+0.7/+0.5**) | 73.2/89.8<br/>(**+2.0/+0.6**) | 86.1<br/>(**+1.5**)     | 85.5<br/>(**+2.1**)      | 92.9<br/>(**+2.4**)   | 74.8<br/>(**+8.4**)  | 65.1                  | 37.4<br/>(**+3.2**) |
| **BERT Large**      | 80.5                       | 60.5                  | 94.9                   | 89.3/85.4                     | 86.5/87.6                     | 72.1/89.3                     | 86.7                    | 85.9                     | 92.7                  | 70.1                 | 65.1                  | 39.6                |
| **ERNIE 2.0 Large** | 83.6<br/>(**+3.1**)        | 63.5<br/>(**+3.0**)   | 95.6<br/>(**+0.7**)    | 90.2/87.4<br/>(**+0.9/+2.0**) | 90.6/91.2<br/>(**+4.1/+3.6**) | 73.8/90.1<br/>(**+1.7/+0.8**) | 88.7<br/>(**+2.0**)     | 88.8<br/>(**+2.9**)      | 94.6<br/>(**+1.9**)   | 80.2<br/>(**+10.1**) | 67.8<br/>(**+2.7**)   | 48.0<br/>(**+8.4**) |

### Продуктивність з китайськими данними
#### Natural Language Inference

| Dataset                                        | XNLI                   |                        |
|------------------------------------------------|------------------------|------------------------|
|                      Metric                    |           acc          |                        |
|                                                |          dev           |          test          |
|          BERT Base                             | 78.1                   | 77.2                   |
|          ERNIE 1.0 Base                        | 79.9 (+1.8)            | 78.4 (+1.2)            |
|          ERNIE 2.0 Base                        | 81.2 (+3.1)            | 79.7 (+2.5)            |
|          ERNIE 2.0 Large                       | 82.6 (+4.5)            | 81.0 (+3.8)            |

#### Machine Reading Comprehension

| Dataset                                        | DuReader              |                            | CMRC2018              |                                     | DRCD                  |                        |                            |                        |
|------------------------------------------------|-----------------------|----------------------------|-----------------------|-------------------------------------|-----------------------|------------------------|----------------------------|------------------------|
|                      Metric                    |           em          |          f1-score          |          em           |          f1-score                   |          em           |                        |          f1-score          |                        |
|                                                |          dev          |                            |          dev          |                                     |          dev          |          test          |          dev               |          test          |
| BERT Base                                      | 59.5                  | 73.1                       | 66.3                  | 85.9                                | 85.7                  | 84.9                   | 91.6                       | 90.9                   |
| ERNIE 1.0 Base                                 | 57.9 (-1.6)           | 72.1 (-1.0)                | 65.1 (-1.2)           | 85.1 (-0.8)                         | 84.6 (-1.1)           | 84.0 (-0.9)            | 90.9 (-0.7)                | 90.5 (-0.4)            |
| ERNIE 2.0 Base                                 | 61.3 (+1.8)           | 74.9 (+1.8)                | 69.1 (+2.8)           | 88.6 (+2.7)                         | 88.5 (+2.8)           | 88.0 (+3.1)            | 93.8 (+2.2)                | 93.4 (+2.5)            |
| ERNIE 2.0 Large                                | 64.2 (+4.7)           | 77.3 (+4.2)                | 71.5 (+5.2)           | 89.9 (+4.0)                         | 89.7 (+4.0)           | 89.0 (+4.1)            | 94.7 (+3.1)                | 94.2 (+3.3)            |

#### Named Entity Recognition

| Dataset                                        | MSRA-NER (SIGHAN2006)       |                        |
|------------------------------------------------|-----------------------------|------------------------|
|                      Metric                    |           f1-score          |                        |
|                                                |          dev                |          test          |
| BERT Base                                      | 94.0                        | 92.6                   |
| ERNIE 1.0 Base                                 | 95.0 (+1.0)                 | 93.8 (+1.2)            |
| ERNIE 2.0 Base                                 | 95.2 (+1.2)                 | 93.8 (+1.2)            |
| ERNIE 2.0 Large                                | 96.3 (+2.3)                 | 95.0 (+2.4)            |

#### Sentiment Analysis Task

| Dataset                                        | ChnSentiCorp           |                        |
|------------------------------------------------|------------------------|------------------------|
|                      Metric                    |           acc          |                        |
|                                                |          dev           |          test          |
| BERT Base                                      | 94.6                   | 94.3                   |
| ERNIE 1.0 Base                                 | 95.2 (+0.6)            | 95.4 (+1.1)            |
| ERNIE 2.0 Base                                 | 95.7 (+1.1)            | 95.5 (+1.2)            |
| ERNIE 2.0 Large                                | 96.1 (+1.5)            | 95.8 (+1.5)            |

#### Question Answering Task

| Datset                                         | NLPCC2016-DBQA         |                        |                             |                        |
|------------------------------------------------|------------------------|------------------------|-----------------------------|------------------------|
|                      Metric                    |           mrr          |                        |           f1-score          |                        |
|                                                |          dev           |          test          |          dev                |          test          |
| BERT Base                                      | 94.7                   | 94.6                   | 80.7                        | 80.8                   |
| ERNIE 1.0 Base                                 | 95.0 (+0.3)            | 95.1 (+0.5)            | 82.3 (+1.6)                 | 82.7 (+1.9)            |
| ERNIE 2.0 Base                                 | 95.7 (+1.0)            | 95.7 (+1.1)            | 84.7 (+4.0)                 | 85.3 (+4.5)            |
| ERNIE 2.0 Large                                | 95.9 (+1.2)            | 95.8 (+1.2)            | 85.3 (+4.6)                 | 85.8 (+5.0)            |



#### Semantic Similarity

| Dataset                                        | LCQMC                 |                        | BQ Corpus             |                        |
|------------------------------------------------|-----------------------|------------------------|-----------------------|------------------------|
|                      Metric                    |           acc         |                        |           acc         |                        |
|                                                |          dev          |          test          |          dev          |          test          |
| BERT Base                                      | 88.8                  | 87.0                   | 85.9                  | 84.8                   |
| ERNIE 1.0 Base                                 | 89.7 (+0.9)           | 87.4 (+0.4)            | 86.1 (+0.2)           | 84.8                   |
| ERNIE 2.0 Base                                 | 90.9 (+2.1)           | 87.9 (+0.9)            | 86.4 (+0.5)           | 85.0 (+0.2)            |
| ERNIE 2.0 Large                                | 90.9 (+2.1)           | 87.9 (+0.9)            | 86.5 (+0.6)           | 85.2 (+0.4)            |

### Ernie 3.0[[12]](https://arxiv.org/pdf/2107.02137)

ERNIE 3.0 — це масштабна модель мови попереднього навчання з покращеним базою знань, випущена Baidu. Вона поєднує в собі авторегресивну та автокодувальну мережеві архітектури, що дозволяє їй ефективно виконувати завдання розуміння природної мови (NLU) та генерації природної мови (NLG) в умовах нульового, малого чи точного налаштування. Модель включає універсальний модуль представлення, який фіксує лексичну та синтаксичну інформацію, що використовується в різних завданнях, та специфічні для завдань модулі для спеціалізованих семантичних представлень.

![ernie3.0](https://miro.medium.com/1*1h26QVSrWSq94IF8UpoMaA.png)
<div align="center"><i>Ernie 3.0 framework</i></div>

ERNIE 3.0 широко застосовується в продуктах штучного інтелекту Baidu, таких як пошук, стрічки новин та розумні колонки, а також доступний для промислового використання через Baidu AI Cloud. Був розроблений більший варіант під назвою ERNIE 3.0 Titan з 260 мільярдами параметрів, який досягає найсучасніших результатів у понад 60 завданнях NLP та демонструє потужні можливості навчання з кількох спроб. ERNIE 3.0 особливо добре використовує світові знання з графів знань у поєднанні з текстовими даними, що підвищує його продуктивність порівняно з текстовими моделями, такими як GPT-3.

#### Продуктивність Ernie 3.0

![superglue](https://research.baidu.com/ueditor/upload/20210712/1626069286263990.png)
ERNIE 3.0 широко застосовується в продуктах штучного інтелекту Baidu, таких як пошук, стрічки новин та розумні колонки, а також доступний для промислового використання через Baidu AI Cloud. Був розроблений більший варіант під назвою ERNIE 3.0 Titan з 260 мільярдами параметрів, який досягає найсучасніших результатів у понад 60 завданнях NLP та демонструє потужні можливості навчання з кількох спроб. ERNIE 3.0 особливо добре використовує світові знання з графів знань у поєднанні з текстовими даними, що підвищує його продуктивність порівняно з текстовими моделями, такими як GPT-3.[[13]](https://research.baidu.com/Blog/index-view?id=160)

Ernie 3.0 також було протестовано з нульовим налаштуванням для різних завдань. За цих параметрів ERNIE 3.0 досяг хороших результатів і перевершив інші великомасштабні мовні моделі того часу, такі як CPM та PanGu.

![cpmpangucomp](https://research.baidu.com/ueditor/upload/20210712/1626069329118575.png)

#### Продуктивність Natural Language Understanding Tasks
![nlut](https://i0.wp.com/syncedreview.com/wp-content/uploads/2021/07/image-71.png?w=790&ssl=1)
![nlut2](https://i0.wp.com/syncedreview.com/wp-content/uploads/2021/07/image-70.png?w=790&ssl=1)

#### Продуктивність Natural Language Generation Tasks
![nlgt](https://miro.medium.com/v2/resize:fit:720/format:webp/1*AYRWNTeEDtzizK4lf9mW5w.png)

#### LUGE Benchmark
![luge](https://miro.medium.com/v2/resize:fit:720/format:webp/1*gn8BCCnMxjhIa2z_XoXnZw.png)

#### Продуктивність Zero-Shot Learning Tasks
![zslt](https://miro.medium.com/v2/resize:fit:720/format:webp/1*ksGWsF4Fz3jcEAwCaNklbg.png)
![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*iShy1hqUHMQSVuFiAwbRlA.png)

Ці високі показники в бенчмарках відображають передову здатність ERNIE 3.0 ефективно поєднувати лексичні, синтаксичні та світові знання в різних мовах програмування та завданнях NLP.

### Ernie 3.5

ERNIE 3.5 — це вдосконалена версія моделі Baidu ERNIE 3.0, представленої у 2023 році як оновлена ​​базова модель великої мови програмування. Спираючись на сильні сторони ERNIE 3.0, ERNIE 3.5 покращує можливості міркування, генерації мови та розуміння. Вона була розроблена для кращої конкуренції з іншими передовими моделями великої мови програмування та помітно зменшує розрив у продуктивності з GPT-4, особливо у завданнях китайської мови та деяких багаточергових розмовних контекстах.

Ця модель отримує користь від збільшеного обсягу навчальних даних та вдосконалених архітектурних покращень, що робить її більш вправною у відповідях на складні запитання, підсумовуванні та дотриманні інструкцій. ERNIE 3.5 слугує основним двигуном для оновлень чат-бота Baidu Ernie Bot приблизно в середині 2023 року, де він продемонстрував значні покращення контекстного розуміння та більш природну взаємодію.

Хоча конкретні параметри та архітектурні деталі менш публічно деталізовані, ніж у ERNIE 3.0, ERNIE 3.5 визнаний тим, що забезпечує суттєвий якісний стрибок у практичних застосуваннях, особливо для китайських випадків використання NLP та мультимодальних завдань, розпочатих пізніше з ERNIE 4.0 та наступними версіями.

#### Продуктивність[[14]](https://gigazine.net/gsc_news/en/20230628-baidu-ernie-3-5/)

Ерні 3.5 у бенчмарку Microsoft Research «AGIEval», який вимірює показники в завданнях, пов'язаних з людським пізнанням та здібностями, та бенчмарку «C-Eval», який вимірює продуктивність китайських студентів, спільно створеному Шанхайським університетом Цзяотун, Університетом Цінхуа та Единбурзьким університетом. «, Університет Берклі, Колумбійський університет, Університет Іллінойсу в Урбана-Шампейн та Чиказький університет спільно випустили бенчмарк «MMLU», який вимірює продуктивність багатозадачності.

У цих тестах виявилося, що Ernie 3.5 перевершив GPT-3.5 у AGIEval та C-Eval, а китайська продуктивність AGIEval та C-Eval була GPT, наступником GPT-3.5. Було підтверджено, що вона перевищила -4.

![](https://i.gzn.jp/img/2023/06/28/baidu-ernie-3-5/02_m.png)

### Ernie 4.0

ERNIE 4.0 — це модель Baidu четвертого покоління для великих мов, представлена ​​в жовтні 2023 року. Вона являє собою значне оновлення порівняно з попередніми версіями ERNIE 3.0 та 3.5, що значно покращує продуктивність чотирьох основних можливостей штучного інтелекту: розуміння природної мови, генерація тексту, міркування та пам'ять. Це вдосконалення дозволяє ERNIE 4.0 краще інтерпретувати складні речення, генерувати більш зв'язний та контекстуально релевантний контент у режимі реального часу, а також вирішувати задачі міркування, такі як геометричні задачі.[[15]](https://kr-asia.com/baidu-claims-its-latest-ai-model-ernie-4-0-is-on-par-with-openais-gpt-4)

Однією з видатних особливостей ERNIE 4.0 є покращена пам'ять, що дозволяє йому краще запам'ятовувати та використовувати вивчені знання для більш обґрунтованих відповідей. Він також може розуміти та інтерпретувати зображення та відеоконтент, розширюючи свої мультимодальні можливості за межі простого тексту. ERNIE 4.0 працює на чат-боті Baidu зі штучним інтелектом "Ernie Bot" та інтегрований у продукти Baidu, такі як Baidu Search, Baidu Maps та Infoflow, що дозволяє цим сервісам надавати багатші функції на основі штучного інтелекту, такі як генерація контенту в режимі реального часу та інтелектуальне підсумовування результатів пошуку.[[16]](https://lucidityinsights.com/news/baidus-ernie-40-unveiled-to-challenge-gpt4)

Baidu позиціонує ERNIE 4.0 як конкурента іншим провідним моделям штучного інтелекту, таким як GPT-4 від OpenAI, серія Turing від Microsoft та Bard від Google, підкреслюючи його сильні можливості в галузі пам'яті, генеративного письма та міркувань. Модель доступна через API для корпоративних додатків, стимулюючи розробку додатків на основі штучного інтелекту та інтелектуальну автоматизацію в різних галузях.[[17]](https://aimode.co/model/ernie-4/)

#### Продуктивність Ernie 4.0 

ERNIE 4.0 було порівняно з провідними моделями великих мов програмування, включаючи GPT-4 від OpenAI, Turing від Microsoft та Bard від Google, для виконання різноманітних завдань, що зосереджуються на розумінні природної мови, генерації, міркуванні та мультимодальних можливостях.[[18]](https://medium.com/@gaurav.gupta24/ernie-vs-gpt-4o-a-comprehensive-comparison-79cf8e69ae11). Ключові порівняння з бенчмарками показали:

- Як у завданнях з китайської, так і з англійської мови, ERNIE 4.0, як повідомляється, відповідає або трохи перевершує показники GPT-4 у багатьох стандартних тестах NLP, таких як розуміння прочитаного, здоровий глузд та багатоповоротний діалог.

- Він особливо перевершує в обробці китайської мови, де значно перевершує GPT-4 завдяки кращій оптимізації рідної мови.

- ERNIE 4.0 демонструє кращу здатність пам'ятати та міркувати у складних завданнях на вирішення проблем, включаючи математичні та логічні головоломки, порівняно з GPT-4 та іншими конкурентами.

- Мультимодальні тести, що включають розуміння зображень та відео, показують, що ERNIE 4.0 конкурентоспроможний з найкращими мультимодальними моделями, що відображає його розширені можливості для контекстного візуального мислення.

- Хоча точні результати різняться залежно від тесту, офіційні заяви Baidu та незалежні аналізи підкреслюють, що ERNIE 4.0 позиціонується як сильний конкурент GPT-4, особливо в мовних завданнях та додатках, орієнтованих на Азію.

Загалом, бенчмаркінг ERNIE 4.0 підкреслює його здатність поєднувати передову інтеграцію знань, міркування та мультимодальні входи на рівнях продуктивності, близьких або відповідних рівням провідних західних моделей штучного інтелекту, таких як GPT-4, за багатьма стандартизованими показниками оцінки ШІ.[[19]](https://kr-asia.com/baidu-claims-its-latest-ai-model-ernie-4-0-is-on-par-with-openais-gpt-4)

### Ernie 4.5

ERNIE 4.5 є наступником ERNIE 4.0, випущеного Baidu на початку 2025 року як частина сімейства мультимодальних моделей великих мов.[[20]](https://ernie.baidu.com/blog/posts/ernie4.5/). Це покоління являє собою стрибок уперед з кількома новими можливостями та архітектурними інноваціями, що робить ERNIE 4.5 надзвичайно універсальним в обробці та міркуванні з використанням різних модальностей, таких як текст, зображення, аудіо та відео.[[21]](https://yiyan.baidu.com/blog/publication/ERNIE_Technical_Report.pdf)

Ключові особливості ERNIE 4.5 включають:

- Мультимодальне розуміння та генерація: ERNIE 4.5 чудово справляється з інтеграцією та обґрунтуванням візуальних та текстових даних, підтримуючи такі завдання, як підписування зображень, підсумовування відео та крос-модальні відповіді на запитання.

- Архітектура суміші експертів (MoE): Вона використовує складний механізм маршрутизації, який ізолює модальності, балансуючи обчислювальні ресурси, що дозволяє ефективно масштабувати до ~424 мільярдів параметрів у різних варіантах без надмірних витрат на висновок.

- Суворе дотримання інструкцій та інтеграція знань: Модель чудово справляється з налаштуванням інструкцій, надаючи точні та контекстно-залежні відповіді на складні запити та багатоетапні задачі обґрунтування.

- Велика родина варіантів: ERNIE 4.5 має понад десять різних варіантів моделей, починаючи від компактних щільних моделей для середовищ з обмеженими ресурсами до масивних моделей MoE для високопродуктивних промислових застосувань.

- Випуск з відкритим вихідним кодом: Baidu оголосила про відкритий вихідний код моделей ERNIE 4.5 та супутнього інструментарію ERNIEKit для точного налаштування та розгортання, сприяючи ширшому впровадженню та інноваціям у дослідженнях та застосуваннях штучного інтелекту.

- Розгортання: ERNIE 4.5 забезпечує роботу вдосконалених версій продуктів штучного інтелекту Baidu, включаючи Ernie Bot, а також підтримує інтелектуальне створення контенту, мультимодальний пошук та робочі навантаження з обробки документів.

ERNIE 4.5 розглядається як найсучасніша мультимодальна система штучного інтелекту, що конкурує на світовому рівні з такими моделями, як GPT-4.5 та іншими передовими LLM, особливо вона досягає успіху в сценаріях, що вимагають складного мультимодального розуміння, запам'ятовування знань та високоадаптивних можливостей логічного висновку.

#### Моделі Ernie 4.5

| Моделі ERNIE 4.5                           |                             | Інформація моделі      |               |                  |
| ------------------------------------------ | --------------------------- | ---------------------- | ------------- | ---------------- |
| Категорія моделі                           | Модель                      | Спосіб вводу           | Спосіб виводу | Контекстне вікно |
| Великі мовні моделі (LLMs)                 | ERNIE-4.5-300B-A47B-Base    | Текст                  | Текст         | 128K             |
|                                            | ERNIE-4.5-300B-A47B         |                        |               |                  |
|                                            | ERNIE-4.5-21B-A3B-Base      |                        |               |                  |
|                                            | ERNIE-4.5-21B-A3B           |                        |               |                  |
| Моделі візуально-мовного сприйняття (VLMs) | ERNIE-4.5-VL-424B-A47B-Base | Текст/Зображення/Відео | Текст         | 128K             |
|                                            | ERNIE-4.5-VL-424B-A47B      |                        |               |                  |
|                                            | ERNIE-4.5-VL-28B-A3B-Base   |                        |               |                  |
|                                            | ERNIE-4.5-VL-28B-A3B        |                        |               |                  |
| Компактні моделі                           | ERNIE-4.5-0.3B-Base         | Текст                  | Текст         | 128K             |
|                                            | ERNIE-4.5-0.3B              |                        |               |                  |


Більш детальний огляд характеристик моделей Ernie 4.5.[[22]](https://blogs.novita.ai/ernie-vram-native-needs-high-novita-ai-needs-zero/)

| Модель                      | Базові параметри | Активні параметри | Тип моделі | Модальність     | Тип навчання |
| --------------------------- | ---------------- | ----------------- | ---------- | --------------- | ------------ |
| ERNIE 4.5 VL 424B A47B      | 424B             | 47B               | MoE        | Текст & Бачення | PT           |
| ERNIE 4.5 VL 424B A47B Base | 424B             | 47B               | MoE        | Текст & Бачення | Base         |
| ERNIE 4.5 VL 28B A3B        | 28B              | 3B                | MoE        | Текст & Бачення | PT           |
| ERNIE 4.5 VL 28B A3B Base   | 28B              | 3B                | MoE        | Текст & Бачення | Base         |
| ERNIE 4.5 300B A47B         | 300B             | 47B               | MoE        | Текст           | PT           |
| ERNIE 4.5 300B A47B Base    | 300B             | 47B               | MoE        | Текст           | Base         |
| ERNIE 4.5 21B A3B           | 21B              | 3B                | MoE        | Текст           | PT           |
| ERNIE 4.5 21B A3B Base      | 21B              | 3B                | MoE        | Текст           | Base         |
| ERNIE 4.5 0.3B              | 0.3B             | –                 | Dense      | Текст           | PT           |
| ERNIE 4.5 0.3B Base         | 0.3B             | –                 | Dense      | Текст           | Base         |


#### Продуктивність Ernie 4.5

ERNIE-4.5-300B-A47B-Base перевершує DeepSeek-V3-671B-A37B-Base у 22 з 28 тестів, демонструючи провідну продуктивність у всіх основних категоріях можливостей. Це підкреслює суттєві покращення в узагальненні, міркуваннях та завданнях, що потребують знань, що сталися завдяки масштабуванню моделі ERNIE-4.5-Base порівняно з іншими сучасними великими моделями. Із загальним розміром параметрів 21B (приблизно 70% від розміру Qwen3-30B), ERNIE-4.5-21B-A3B-Base перевершує Qwen3-30B-A3B-Base у кількох математичних та логічних тестах, включаючи BBH та CMATH. ERNIE-4.5-21B-A3B-Base залишається дуже конкурентоспроможною, враховуючи значно менший розмір моделі, демонструючи значну ефективність параметрів та вигідні компроміси в продуктивності.[[23]](https://github.com/PaddlePaddle/ERNIE)

#### Продуктивність попередньо навчених моделей ERNIE-4.5

![](https://camo.githubusercontent.com/ddd95f5cdcdf354f2f7de788742ba684a9db962270c8aabac44bfbebce9a4207/68747470733a2f2f796979616e2e62616964752e636f6d2f626c6f672f706f7374732f65726e6965342e352f626173655f6d6f64656c5f62656e63686d61726b2e706e67)

#### Продуктивність остаточно навченої моделі ERNIE-4.5-300B-A47B

![](https://camo.githubusercontent.com/3c98b957a09accc63fd36285a140bd8a474d061a2f24b8a71535309820000742/68747470733a2f2f796979616e2e62616964752e636f6d2f626c6f672f706f7374732f65726e6965342e352f636861745f6d6f64656c5f62656e63686d61726b312e706e67)

#### Продуктивність остаточно навченої моделі ERNIE-4.5-21B-A3B

![](https://miro.medium.com/v2/resize:fit:720/format:webp/0*ESNXOvCpcaeANvMe)

#### Продуктивність остаточно навчених модель в режимі мислення

![](https://camo.githubusercontent.com/5ffa942cf3417c6d2a343a74eb70f964f76ed45635fc94cafc7745a10b9ff7d3/68747470733a2f2f796979616e2e62616964752e636f6d2f626c6f672f706f7374732f65726e6965342e352f766c5f6d6f64656c5f7468696e6b696e675f62656e63686d61726b2e706e67)

#### Продуктивність остаточно навчених модель в режимі немислення

![](https://i0.wp.com/blogs.novita.ai/wp-content/uploads/2025/07/9fbcfdf4-5858-40f0-8d60-2d497861f42d.jpeg?resize=1024%2C905&ssl=1)

### Ernie X1

ERNIE X1 — це спеціалізована модель глибокого мислення від Baidu, анонсована у березні 2025 року як частина лінійки моделей великих мов наступного покоління. Вона розроблена для досягнення успіху в завданнях розширеного мислення, планування, рефлексії та еволюції, що відрізняє її від універсального сімейства моделей ERNIE 4.5. ERNIE X1 підтримує мультимодальні можливості, включаючи розуміння тексту, зображень, аудіо та відео, і є першою моделлю штучного інтелекту Baidu, здатною використовувати такі інструменти, як розширений пошук, відповіді на запитання щодо документів, розуміння зображень, генерація зображень за допомогою штучного інтелекту та читання веб-сторінок.

Модель включає кілька інноваційних технологій, таких як динамічне маскування уваги "FlashMask" та гетерогенну мультимодальну архітектуру зі змішаними експертами, що підвищує її ефективність та результативність. ERNIE X1 продемонструвала високу продуктивність у питаннях та відповідях на знання китайської мови, літературній творчості, діалозі, логічних міркуваннях та складних обчисленнях. Вона забезпечує продуктивність, порівнянну з провідними моделями, такими як DeepSeek R1, але приблизно за вдвічі меншими експлуатаційними витратами.[[24]](https://xpert.digital/en/baidu-reaches-with-its-new-ai-models/)

У вересні 2025 року Baidu випустила ERNIE X1.1, оновлену версію X1, яка суттєво покращує фактичну точність (на 34,8%), відстеження інструкцій (на 12,5% краще) та агентські можливості (покращення на 9,6%). ERNIE X1.1 відповідає продуктивності моделей вищого рівня, таких як GPT-5 та Gemini 2.5 Pro, водночас є більш економічно ефективною.[[25]](https://overchat.ai/models/ernie-x1-1#:~:text=ERNIE%20X1.1%20is%20Baidu's%20newest%20AI%20model%20released%20in%20September%202025)

### Ernie 5.0

ERNIE 5.0 — це модель великої мови програмування наступного покоління, анонсована Baidu у 2025 році як наступник сімейства ERNIE 4.5.[[26]](https://global.chinadaily.com.cn/a/202511/13/WS691571bda310d6866eb29500.html) Вона являє собою значний прогрес у масштабуванні та архітектурі, що включає найновіші інновації в технології залучення експертів (MoE) та мультимодальному навчанні.

Ключові аспекти ERNIE 5.0 включають:

- Надзвичайно великий масштаб параметрів, із запланованими конфігураціями, що сягають приблизно 2,4 трильйона параметрів, що робить її однією з найбільших моделей MoE у світі.

- Розширені мультимодальні можливості з покращеною інтеграцією та міркуваннями щодо тексту, зображень, аудіо та відео вхідних даних.

- Удосконалені алгоритми навчання для покращення виконання інструкцій, міркувань, пам'яті та узагальнення порівняно з попередніми версіями ERNIE.

- Розроблено для подальшого скорочення розриву з провідними міжнародними моделями, такими як GPT-4.5 та серії Gemini, або їх перевершення в бенчмарках та реальних застосуваннях.

- Очікується, що прискорить розвиток екосистеми штучного інтелекту Baidu завдяки ширшим випускам з відкритим кодом та розширеним хмарним сервісам штучного інтелекту.

Хоча детальні технічні специфікації та публічні бенчмарки ще не були опубліковані, ERNIE 5.0 позиціонується як найсучасніша базова модель штучного інтелекту як для промислового, так і для дослідницького використання, продовжуючи шлях Baidu до високопараметричних, мультимодальних моделей великої мови програмування з сильними можливостями міркування та знань.

### Продуктивність ERNIE-5.0-Preview-1022 у LMArena

У листопаді 2025 року Baidu випустила попередню версію Ernie 5.0. Це рання версія, випущена як уявлення про можливості великої мовної моделі Baidu наступного покоління. Вона слугує технологічною демонстрацією досягнень у масштабуванні, мультимодальній інтеграції та міркуванні, запроваджених в ERNIE 5.0.[[27]](https://ernie.baidu.com/blog/posts/ernie-5.0-preview-1022-release-on-lmarena/)

![](https://ernie.baidu.com/blog/posts/ernie-5.0-preview-1022-release-on-lmarena/ernie-5.0-preview-1022-release-on-lmarena.png)